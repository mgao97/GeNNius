====================================================================================================
data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={ edge_index=[2, 13838] },
  (protein, rev_interaction, drug)={ edge_index=[2, 13838] }
)
====================================================================================================
****************************************************************************************************
train data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 7751],
    edge_label=[5811],
    edge_label_index=[2, 5811],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 7751] }
)
****************************************************************************************************
val data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 9688],
    edge_label=[4149],
    edge_label_index=[2, 4149],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 9688] }
)
****************************************************************************************************
test data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 11071],
    edge_label=[8301],
    edge_label_index=[2, 8301],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 11071] }
)
****************************************************************************************************
edge_x: torch.Size([5811, 32])
labels: torch.Size([5811])
edge_x: torch.Size([4149, 32])
labels: torch.Size([4149])
edge_x: torch.Size([8301, 32])
labels: torch.Size([8301])
model: HGT(
  (lin_dict): ModuleDict(
    (drug): Linear(-1, 64, bias=True)
    (protein): Linear(-1, 64, bias=True)
  )
  (convs): ModuleList(
    (0-1): 2 x HGTConv(-1, 64, heads=1)
  )
  (lin): Linear(128, 1, bias=True)
)
Epoch: 51, Loss: 0.5115
Epoch: 101, Loss: 0.4928
Epoch: 151, Loss: 0.4755
Epoch: 201, Loss: 0.4709
Epoch: 251, Loss: 0.4737
Epoch: 301, Loss: 0.4662
Epoch: 351, Loss: 0.4620
Epoch: 401, Loss: 0.4602
Epoch: 451, Loss: 0.4593
Epoch: 501, Loss: 0.4562
Epoch: 551, Loss: 0.4525
Epoch: 601, Loss: 0.4522
Epoch: 651, Loss: 0.4496
Epoch: 701, Loss: 0.4630
Epoch: 751, Loss: 0.4481
Epoch: 801, Loss: 0.4455
Epoch: 851, Loss: 0.4449
Epoch: 901, Loss: 0.4436
Epoch: 951, Loss: 0.4441
Epoch: 1001, Loss: 0.4365
Epoch: 51, Loss: 0.4388
Epoch: 101, Loss: 0.4441
Epoch: 151, Loss: 0.4313
Epoch: 201, Loss: 0.4310
Epoch: 251, Loss: 0.4428
Epoch: 301, Loss: 0.4316
Epoch: 351, Loss: 0.4281
Epoch: 401, Loss: 0.4285
Epoch: 451, Loss: 0.4269
Epoch: 501, Loss: 0.4484
Epoch: 551, Loss: 0.5004
Epoch: 601, Loss: 0.5066
Epoch: 651, Loss: 0.4515
Epoch: 701, Loss: 0.4437
Epoch: 751, Loss: 0.4324
Epoch: 801, Loss: 0.4419
Epoch: 851, Loss: 0.4297
Epoch: 901, Loss: 0.4313
Epoch: 951, Loss: 0.4282
Epoch: 1001, Loss: 0.4275
Elapsed time 0.0825 min
Epoch: 51, Loss: 0.4241
Epoch: 101, Loss: 0.4288
Epoch: 151, Loss: 0.4192
Epoch: 201, Loss: 0.4334
Epoch: 251, Loss: 0.4178
Epoch: 301, Loss: 0.4163
Epoch: 351, Loss: 0.4152
Epoch: 401, Loss: 0.4158
Epoch: 451, Loss: 0.4158
Epoch: 501, Loss: 0.4117
Epoch: 551, Loss: 0.4077
Epoch: 601, Loss: 0.4068
Epoch: 651, Loss: 0.3985
Epoch: 701, Loss: 0.4022
Epoch: 751, Loss: 0.4079
Epoch: 801, Loss: 0.3929
Epoch: 851, Loss: 0.3896
Epoch: 901, Loss: 0.3898
Epoch: 951, Loss: 0.3895
Epoch: 1001, Loss: 0.3847
Elapsed time 0.0834 min
Epoch: 51, Loss: 0.3930
Epoch: 101, Loss: 0.3785
Epoch: 151, Loss: 0.3751
Epoch: 201, Loss: 0.3803
Epoch: 251, Loss: 0.3814
Epoch: 301, Loss: 0.3692
Epoch: 351, Loss: 0.3670
Epoch: 401, Loss: 0.3688
Epoch: 451, Loss: 0.3659
Epoch: 501, Loss: 0.4094
Epoch: 551, Loss: 0.3830
Epoch: 601, Loss: 0.3787
Epoch: 651, Loss: 0.3653
Epoch: 701, Loss: 0.3640
Epoch: 751, Loss: 0.3609
Epoch: 801, Loss: 0.3602
Epoch: 851, Loss: 0.3548
Epoch: 901, Loss: 0.3549
Epoch: 951, Loss: 0.3606
Epoch: 1001, Loss: 0.3600
Elapsed time 0.0830 min
Epoch: 51, Loss: 0.3635
Epoch: 101, Loss: 0.3509
Epoch: 151, Loss: 0.3597
Epoch: 201, Loss: 0.3491
Epoch: 251, Loss: 0.3787
Epoch: 301, Loss: 0.3468
Epoch: 351, Loss: 0.3460
Epoch: 401, Loss: 0.3588
Epoch: 451, Loss: 0.3418
Epoch: 501, Loss: 0.3431
Epoch: 551, Loss: 0.3475
Epoch: 601, Loss: 0.3411
Epoch: 651, Loss: 0.3398
Epoch: 701, Loss: 0.3413
Epoch: 751, Loss: 0.3352
Epoch: 801, Loss: 0.4356
Epoch: 851, Loss: 0.4120
Epoch: 901, Loss: 0.4016
Epoch: 951, Loss: 0.3930
Epoch: 1001, Loss: 0.3891
Elapsed time 0.0830 min
Epoch: 51, Loss: 0.3839
Epoch: 101, Loss: 0.3847
Epoch: 151, Loss: 0.3788
Epoch: 201, Loss: 0.3750
Epoch: 251, Loss: 0.3753
Epoch: 301, Loss: 0.3675
Epoch: 351, Loss: 0.3695
Epoch: 401, Loss: 0.3649
Epoch: 451, Loss: 0.3596
Epoch: 501, Loss: 0.3621
Epoch: 551, Loss: 0.3581
Epoch: 601, Loss: 0.3656
Epoch: 651, Loss: 0.3547
Epoch: 701, Loss: 0.3509
Epoch: 751, Loss: 0.3488
Epoch: 801, Loss: 0.3578
Epoch: 851, Loss: 0.3539
Epoch: 901, Loss: 0.3419
Epoch: 951, Loss: 0.3422
Epoch: 1001, Loss: 0.3647
Elapsed time 0.0837 min
Epoch: 51, Loss: 0.3639
Epoch: 101, Loss: 0.3478
Epoch: 151, Loss: 0.3458
Epoch: 201, Loss: 0.3403
Epoch: 251, Loss: 0.3443
Epoch: 301, Loss: 0.4068
Epoch: 351, Loss: 0.3749
Epoch: 401, Loss: 0.3641
Epoch: 451, Loss: 0.3556
Epoch: 501, Loss: 0.3514
Epoch: 551, Loss: 0.4239
Epoch: 601, Loss: 0.3713
Epoch: 651, Loss: 0.3586
Epoch: 701, Loss: 0.3807
Epoch: 751, Loss: 0.3560
Epoch: 801, Loss: 0.3513
Epoch: 851, Loss: 0.3616
Epoch: 901, Loss: 0.3586
Epoch: 951, Loss: 0.4020
Epoch: 1001, Loss: 0.3661
Elapsed time 0.0828 min
Epoch: 51, Loss: 0.3549
Epoch: 101, Loss: 0.3483
Epoch: 151, Loss: 0.3435
Epoch: 201, Loss: 0.3442
Epoch: 251, Loss: 0.3590
Epoch: 301, Loss: 0.3412
Epoch: 351, Loss: 0.3600
Epoch: 401, Loss: 0.3396
Epoch: 451, Loss: 0.3504
Epoch: 501, Loss: 0.4261
Epoch: 551, Loss: 0.3994
Epoch: 601, Loss: 0.3881
Epoch: 651, Loss: 0.3736
Epoch: 701, Loss: 0.5972
Epoch: 751, Loss: 0.4417
Epoch: 801, Loss: 0.4360
Epoch: 851, Loss: 0.4251
Epoch: 901, Loss: 0.4159
Epoch: 951, Loss: 0.4104
Epoch: 1001, Loss: 0.4058
Elapsed time 0.0862 min
Epoch: 51, Loss: 0.4320
Epoch: 101, Loss: 0.4094
Epoch: 151, Loss: 0.4374
Epoch: 201, Loss: 0.4228
Epoch: 251, Loss: 0.4167
Epoch: 301, Loss: 0.4125
Epoch: 351, Loss: 0.4086
Epoch: 401, Loss: 0.4063
Epoch: 451, Loss: 0.4031
Epoch: 501, Loss: 0.4007
Epoch: 551, Loss: 0.3965
Epoch: 601, Loss: 0.3953
Epoch: 651, Loss: 0.3896
Epoch: 701, Loss: 0.3924
Epoch: 751, Loss: 0.3956
Epoch: 801, Loss: 0.3875
Epoch: 851, Loss: 0.3949
Epoch: 901, Loss: 0.3878
Epoch: 951, Loss: 0.3869
Epoch: 1001, Loss: 0.3802
Elapsed time 0.0862 min
Epoch: 51, Loss: 0.3784
Epoch: 101, Loss: 0.3849
Epoch: 151, Loss: 0.3922
Epoch: 201, Loss: 0.4169
Epoch: 251, Loss: 0.3810
Epoch: 301, Loss: 0.3756
Epoch: 351, Loss: 0.3810
Epoch: 401, Loss: 0.3713
Epoch: 451, Loss: 0.3738
Epoch: 501, Loss: 0.3680
Epoch: 551, Loss: 0.3669
Epoch: 601, Loss: 0.4894
Epoch: 651, Loss: 0.4260
Epoch: 701, Loss: 0.4186
Epoch: 751, Loss: 0.4132
Epoch: 801, Loss: 0.4087
Epoch: 851, Loss: 0.4059
Epoch: 901, Loss: 0.4040
Epoch: 951, Loss: 0.4016
Epoch: 1001, Loss: 0.3966
Elapsed time 0.0864 min
Epoch: 51, Loss: 0.3934
Epoch: 101, Loss: 0.3931
Epoch: 151, Loss: 0.3859
Epoch: 201, Loss: 0.3831
Epoch: 251, Loss: 0.3797
Epoch: 301, Loss: 0.3907
Epoch: 351, Loss: 0.4562
Epoch: 401, Loss: 0.4709
Epoch: 451, Loss: 0.4529
Epoch: 501, Loss: 0.4427
Epoch: 551, Loss: 0.4385
Epoch: 601, Loss: 0.4356
Epoch: 651, Loss: 0.4381
Epoch: 701, Loss: 0.4328
Epoch: 751, Loss: 0.4310
Epoch: 801, Loss: 0.4282
Epoch: 851, Loss: 0.4268
Epoch: 901, Loss: 0.4211
Epoch: 951, Loss: 0.4196
Epoch: 1001, Loss: 0.4153
Elapsed time 0.0861 min
avg Test Accuracy: 0.8202  avg Test AUC: 0.8781  avg Test PRE: 0.7610
