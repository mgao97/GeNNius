[INFO] hidden channels: 64]
Dataset:  drugbank
reading from Data/DRUGBANK/hetero_data_drugbank.pt
hd:  64
cuda
Data is cuda?: True
data HeteroData(
  drug={
    node_id=[6823],
    x=[6823, 12],
  },
  protein={
    node_id=[4650],
    x=[4650, 20],
  },
  (drug, interaction, protein)={ edge_index=[2, 23705] },
  (protein, rev_interaction, drug)={ edge_index=[2, 23705] }
)
train_data HeteroData(
  drug={
    node_id=[6823],
    x=[6823, 12],
  },
  protein={
    node_id=[4650],
    x=[4650, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 13276],
    edge_label=[9954],
    edge_label_index=[2, 9954],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 13276] }
)
model: Model(
  (encoder): GraphModule(
    (conv_in): ModuleDict(
      (drug__interaction__protein): SAGEConv((-1, -1), 64, aggr=sum)
      (protein__rev_interaction__drug): SAGEConv((-1, -1), 64, aggr=sum)
    )
    (act): ModuleDict(
      (drug): Tanh()
      (protein): Tanh()
    )
    (dropout): ModuleDict(
      (drug): Dropout(p=0.2, inplace=False)
      (protein): Dropout(p=0.2, inplace=False)
    )
    (conv_med): ModuleDict(
      (drug__interaction__protein): SAGEConv((-1, -1), 64, aggr=sum)
      (protein__rev_interaction__drug): SAGEConv((-1, -1), 64, aggr=sum)
    )
    (conv_out): ModuleDict(
      (drug__interaction__protein): SAGEConv((-1, -1), 64, aggr=sum)
      (protein__rev_interaction__drug): SAGEConv((-1, -1), 64, aggr=sum)
    )
  )
  (decoder): EdgeClassifier(
    (lin1): Linear(in_features=128, out_features=64, bias=True)
    (lin2): Linear(in_features=64, out_features=1, bias=True)
  )
)
early stopped at epoch  42
Epoch: 050, Loss: 0.4278, Train: 0.8745, Val: 0.8780, Test: 0.8851
Epoch: 100, Loss: 0.4238, Train: 0.8777, Val: 0.8797, Test: 0.8858
Epoch: 150, Loss: 0.4212, Train: 0.8818, Val: 0.8823, Test: 0.8873
Epoch: 200, Loss: 0.4207, Train: 0.8827, Val: 0.8844, Test: 0.8894
Epoch: 250, Loss: 0.4202, Train: 0.8864, Val: 0.8893, Test: 0.8944
Epoch: 300, Loss: 0.4151, Train: 0.8881, Val: 0.8930, Test: 0.8988
Epoch: 350, Loss: 0.4141, Train: 0.8876, Val: 0.8943, Test: 0.9003
Epoch: 400, Loss: 0.4081, Train: 0.8890, Val: 0.8948, Test: 0.9009
Epoch: 450, Loss: 0.4091, Train: 0.8856, Val: 0.8911, Test: 0.8969
Epoch: 500, Loss: 0.4024, Train: 0.8873, Val: 0.8927, Test: 0.8991
Epoch: 550, Loss: 0.4057, Train: 0.8891, Val: 0.8932, Test: 0.9001
Epoch: 600, Loss: 0.3972, Train: 0.8920, Val: 0.8958, Test: 0.9033
Epoch: 650, Loss: 0.3960, Train: 0.8935, Val: 0.8960, Test: 0.9031
Epoch: 700, Loss: 0.3976, Train: 0.8940, Val: 0.8958, Test: 0.9029
Epoch: 750, Loss: 0.3899, Train: 0.8959, Val: 0.8983, Test: 0.9066
Epoch: 800, Loss: 0.3849, Train: 0.8973, Val: 0.8986, Test: 0.9072
Epoch: 850, Loss: 0.3826, Train: 0.8971, Val: 0.9004, Test: 0.9093
Epoch: 900, Loss: 0.3823, Train: 0.8989, Val: 0.9000, Test: 0.9097
Epoch: 950, Loss: 0.3806, Train: 0.9007, Val: 0.9028, Test: 0.9125
Epoch: 1000, Loss: 0.3795, Train: 0.8999, Val: 0.9010, Test: 0.9106
Epoch: 050, Loss: 0.3903, Train: 0.9011, Val: 0.9039, Test: 0.9134
Epoch: 100, Loss: 0.3756, Train: 0.8999, Val: 0.9017, Test: 0.9099
Epoch: 150, Loss: 0.3886, Train: 0.9012, Val: 0.9044, Test: 0.9136
early stopped at epoch  174
early stopped at epoch  43
Epoch: 050, Loss: 0.3761, Train: 0.9023, Val: 0.9046, Test: 0.9136
Epoch: 100, Loss: 0.3741, Train: 0.9014, Val: 0.9042, Test: 0.9121
Epoch: 150, Loss: 0.3742, Train: 0.9017, Val: 0.9039, Test: 0.9126
Epoch: 200, Loss: 0.3720, Train: 0.9004, Val: 0.9034, Test: 0.9118
Epoch: 250, Loss: 0.3699, Train: 0.9019, Val: 0.9048, Test: 0.9137
Epoch: 300, Loss: 0.3698, Train: 0.9027, Val: 0.9046, Test: 0.9141
Epoch: 350, Loss: 0.3697, Train: 0.9024, Val: 0.9046, Test: 0.9133
Epoch: 400, Loss: 0.3813, Train: 0.9024, Val: 0.9034, Test: 0.9117
Epoch: 450, Loss: 0.3719, Train: 0.9028, Val: 0.9039, Test: 0.9133
Epoch: 500, Loss: 0.3703, Train: 0.9032, Val: 0.9047, Test: 0.9133
Epoch: 550, Loss: 0.3735, Train: 0.9035, Val: 0.9048, Test: 0.9136
Epoch: 600, Loss: 0.3720, Train: 0.9020, Val: 0.9035, Test: 0.9130
Epoch: 650, Loss: 0.3702, Train: 0.9028, Val: 0.9043, Test: 0.9129
Epoch: 700, Loss: 0.3734, Train: 0.9031, Val: 0.9049, Test: 0.9135
Epoch: 750, Loss: 0.3694, Train: 0.9029, Val: 0.9050, Test: 0.9132
Epoch: 800, Loss: 0.3671, Train: 0.9032, Val: 0.9048, Test: 0.9133
Epoch: 850, Loss: 0.3716, Train: 0.9034, Val: 0.9055, Test: 0.9143
Epoch: 900, Loss: 0.3687, Train: 0.9043, Val: 0.9053, Test: 0.9136
Epoch: 950, Loss: 0.3739, Train: 0.9049, Val: 0.9072, Test: 0.9155
Epoch: 1000, Loss: 0.3680, Train: 0.9058, Val: 0.9076, Test: 0.9155
Epoch: 050, Loss: 0.3679, Train: 0.9065, Val: 0.9076, Test: 0.9155
Epoch: 100, Loss: 0.3709, Train: 0.9049, Val: 0.9070, Test: 0.9154
Epoch: 150, Loss: 0.3617, Train: 0.9050, Val: 0.9069, Test: 0.9148
Epoch: 200, Loss: 0.3629, Train: 0.9059, Val: 0.9063, Test: 0.9147
Epoch: 250, Loss: 0.3641, Train: 0.9047, Val: 0.9052, Test: 0.9127
Epoch: 300, Loss: 0.3655, Train: 0.9055, Val: 0.9067, Test: 0.9151
Epoch: 350, Loss: 0.3631, Train: 0.9058, Val: 0.9069, Test: 0.9153
Epoch: 400, Loss: 0.3671, Train: 0.9067, Val: 0.9080, Test: 0.9165
Epoch: 450, Loss: 0.3628, Train: 0.9065, Val: 0.9074, Test: 0.9161
Epoch: 500, Loss: 0.3638, Train: 0.9056, Val: 0.9068, Test: 0.9150
early stopped at epoch  507
early stopped at epoch  41
Epoch: 050, Loss: 0.6367, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 100, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 150, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 200, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 250, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 300, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 350, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 400, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 450, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 500, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 550, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 600, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 650, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 700, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 750, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 800, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 850, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 900, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 950, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 1000, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 050, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 100, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 150, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 200, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 250, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 300, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 350, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 400, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 450, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 500, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 550, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 600, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 650, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 700, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 750, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 800, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 850, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 900, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 950, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 1000, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 050, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 100, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 150, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 200, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 250, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 300, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 350, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 400, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 450, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 500, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 550, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 600, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 650, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 700, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 750, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 800, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 850, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 900, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 950, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 1000, Loss: 0.6365, Train: 0.5000, Val: 0.5000, Test: 0.5000
 
avg Test Accuracy: 0.7750  avg Test AUC: 0.7454  avg Test PRE: 0.6448
Elapsed time 1.6611 min
plotting loss over epochs
plotting loss over epochs
plotting loss over epochs
