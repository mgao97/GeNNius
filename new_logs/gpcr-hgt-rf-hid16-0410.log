====================================================================================================
data: HeteroData(
  drug={ x=[222, 12] },
  protein={ x=[94, 20] },
  (drug, interaction, protein)={ edge_index=[2, 634] },
  (protein, rev_interaction, drug)={ edge_index=[2, 634] }
)
====================================================================================================
****************************************************************************************************
train data: HeteroData(
  drug={ x=[222, 12] },
  protein={ x=[94, 20] },
  (drug, interaction, protein)={
    edge_index=[2, 356],
    edge_label=[267],
    edge_label_index=[2, 267],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 356] }
)
****************************************************************************************************
val data: HeteroData(
  drug={ x=[222, 12] },
  protein={ x=[94, 20] },
  (drug, interaction, protein)={
    edge_index=[2, 445],
    edge_label=[189],
    edge_label_index=[2, 189],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 445] }
)
****************************************************************************************************
test data: HeteroData(
  drug={ x=[222, 12] },
  protein={ x=[94, 20] },
  (drug, interaction, protein)={
    edge_index=[2, 508],
    edge_label=[378],
    edge_label_index=[2, 378],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 508] }
)
****************************************************************************************************
edge_x: torch.Size([267, 32])
labels: torch.Size([267])
edge_x: torch.Size([189, 32])
labels: torch.Size([189])
edge_x: torch.Size([378, 32])
labels: torch.Size([378])
model: HGT(
  (lin_dict): ModuleDict(
    (drug): Linear(-1, 16, bias=True)
    (protein): Linear(-1, 16, bias=True)
  )
  (convs): ModuleList(
    (0-3): 4 x HGTConv(-1, 16, heads=2)
  )
  (lin): Linear(32, 1, bias=True)
)
Epoch: 51, Loss: 0.4889
Epoch: 101, Loss: 0.4683
Epoch: 151, Loss: 0.5664
Epoch: 201, Loss: 0.5084
Epoch: 251, Loss: 0.4850
Epoch: 301, Loss: 0.4904
Epoch: 351, Loss: 0.4602
Epoch: 401, Loss: 0.4801
Epoch: 451, Loss: 0.4615
Epoch: 501, Loss: 0.4541
Epoch: 551, Loss: 0.4705
Epoch: 601, Loss: 0.4877
Epoch: 651, Loss: 0.4693
Epoch: 701, Loss: 0.4542
Epoch: 751, Loss: 0.4611
Epoch: 801, Loss: 0.4505
Epoch: 851, Loss: 0.4412
Epoch: 901, Loss: 0.4370
Epoch: 951, Loss: 0.4419
Epoch: 1001, Loss: 0.4255
Elapsed time 0.1049 min
Epoch: 51, Loss: 0.4202
Epoch: 101, Loss: 0.4236
Epoch: 151, Loss: 0.4170
Epoch: 201, Loss: 0.4397
Epoch: 251, Loss: 0.4079
Epoch: 301, Loss: 0.4380
Epoch: 351, Loss: 0.4270
Epoch: 401, Loss: 0.4715
Epoch: 451, Loss: 0.4305
Epoch: 501, Loss: 0.4613
Epoch: 551, Loss: 0.4476
Epoch: 601, Loss: 0.4446
Epoch: 651, Loss: 0.4429
Epoch: 701, Loss: 0.4413
Epoch: 751, Loss: 0.4396
Epoch: 801, Loss: 0.4362
Epoch: 851, Loss: 0.4316
Epoch: 901, Loss: 0.4593
Epoch: 951, Loss: 0.4469
Epoch: 1001, Loss: 0.4413
Elapsed time 0.1041 min
Epoch: 51, Loss: 0.4379
Epoch: 101, Loss: 0.4349
Epoch: 151, Loss: 0.4326
Epoch: 201, Loss: 0.4285
Epoch: 251, Loss: 0.4259
Epoch: 301, Loss: 0.4236
Epoch: 351, Loss: 0.4213
Epoch: 401, Loss: 0.4211
Epoch: 451, Loss: 0.4193
Epoch: 501, Loss: 0.4194
Epoch: 551, Loss: 0.4175
Epoch: 601, Loss: 0.4158
Epoch: 651, Loss: 0.4152
Epoch: 701, Loss: 0.4131
Epoch: 751, Loss: 0.4172
Epoch: 801, Loss: 0.4032
Epoch: 851, Loss: 0.4164
Epoch: 901, Loss: 0.4223
Epoch: 951, Loss: 0.4135
Epoch: 1001, Loss: 0.4896
Elapsed time 0.1040 min
Epoch: 51, Loss: 0.4585
Epoch: 101, Loss: 0.4445
Epoch: 151, Loss: 0.4375
Epoch: 201, Loss: 0.4345
Epoch: 251, Loss: 0.4126
Epoch: 301, Loss: 0.4499
Epoch: 351, Loss: 0.4232
Epoch: 401, Loss: 0.6084
Epoch: 451, Loss: 0.5186
Epoch: 501, Loss: 0.5033
Epoch: 551, Loss: 0.4890
Epoch: 601, Loss: 0.4824
Epoch: 651, Loss: 0.4797
Epoch: 701, Loss: 0.4769
Epoch: 751, Loss: 0.4728
Epoch: 801, Loss: 0.4705
Epoch: 851, Loss: 0.4695
Epoch: 901, Loss: 0.4686
Epoch: 951, Loss: 0.4653
Epoch: 1001, Loss: 0.4655
Elapsed time 0.1041 min
Epoch: 51, Loss: 0.4612
Epoch: 101, Loss: 0.4592
Epoch: 151, Loss: 0.4574
Epoch: 201, Loss: 0.4577
Epoch: 251, Loss: 0.4594
Epoch: 301, Loss: 0.4578
Epoch: 351, Loss: 0.4563
Epoch: 401, Loss: 0.4834
Epoch: 451, Loss: 0.4831
Epoch: 501, Loss: 0.4823
Epoch: 551, Loss: 0.4820
Epoch: 601, Loss: 0.4892
Epoch: 651, Loss: 0.4779
Epoch: 701, Loss: 0.4773
Epoch: 751, Loss: 0.4835
Epoch: 801, Loss: 0.4782
Epoch: 851, Loss: 0.4782
Epoch: 901, Loss: 0.4787
Epoch: 951, Loss: 0.4777
Epoch: 1001, Loss: 0.4775
Elapsed time 0.1041 min
Epoch: 51, Loss: 0.4758
Epoch: 101, Loss: 0.4883
Epoch: 151, Loss: 0.4734
Epoch: 201, Loss: 0.4817
Epoch: 251, Loss: 0.4725
Epoch: 301, Loss: 0.5152
Epoch: 351, Loss: 0.5054
Epoch: 401, Loss: 0.5018
Epoch: 451, Loss: 0.4996
Epoch: 501, Loss: 0.4987
Epoch: 551, Loss: 0.4983
Epoch: 601, Loss: 0.5004
Epoch: 651, Loss: 0.4976
Epoch: 701, Loss: 0.4960
Epoch: 751, Loss: 0.4937
Epoch: 801, Loss: 0.4931
Epoch: 851, Loss: 0.5061
Epoch: 901, Loss: 0.4938
Epoch: 951, Loss: 0.4936
Epoch: 1001, Loss: 0.4938
Elapsed time 0.1041 min
Epoch: 51, Loss: 0.4933
Epoch: 101, Loss: 0.4923
Epoch: 151, Loss: 0.4925
Epoch: 201, Loss: 0.4929
Epoch: 251, Loss: 0.4929
Epoch: 301, Loss: 0.4921
Epoch: 351, Loss: 0.4917
Epoch: 401, Loss: 0.4919
Epoch: 451, Loss: 0.4918
Epoch: 501, Loss: 0.4921
Epoch: 551, Loss: 0.4937
Epoch: 601, Loss: 0.4917
Epoch: 651, Loss: 0.4919
Epoch: 701, Loss: 0.4913
Epoch: 751, Loss: 0.4912
Epoch: 801, Loss: 0.4910
Epoch: 851, Loss: 0.4908
Epoch: 901, Loss: 0.4914
Epoch: 951, Loss: 0.4922
Epoch: 1001, Loss: 0.4906
Elapsed time 0.1026 min
Epoch: 51, Loss: 0.4914
Epoch: 101, Loss: 0.4906
Epoch: 151, Loss: 0.4901
Epoch: 201, Loss: 0.4913
Epoch: 251, Loss: 0.4905
Epoch: 301, Loss: 0.4913
Epoch: 351, Loss: 0.4905
Epoch: 401, Loss: 0.4900
Epoch: 451, Loss: 0.4912
Epoch: 501, Loss: 0.4909
Epoch: 551, Loss: 0.4882
Epoch: 601, Loss: 0.4879
Epoch: 651, Loss: 0.5103
Epoch: 701, Loss: 0.4910
Epoch: 751, Loss: 0.4752
Epoch: 801, Loss: 0.4612
Epoch: 851, Loss: 0.4605
Epoch: 901, Loss: 0.4605
Epoch: 951, Loss: 0.4601
Epoch: 1001, Loss: 0.4598
Elapsed time 0.1007 min
Epoch: 51, Loss: 0.4595
Epoch: 101, Loss: 0.4596
Epoch: 151, Loss: 0.4588
Epoch: 201, Loss: 0.4586
Epoch: 251, Loss: 0.4590
Epoch: 301, Loss: 0.4584
Epoch: 351, Loss: 0.4579
Epoch: 401, Loss: 0.4576
Epoch: 451, Loss: 0.4574
Epoch: 501, Loss: 0.4568
Epoch: 551, Loss: 0.4565
Epoch: 601, Loss: 0.4570
Epoch: 651, Loss: 0.4552
Epoch: 701, Loss: 0.4561
Epoch: 751, Loss: 0.4534
Epoch: 801, Loss: 0.4522
Epoch: 851, Loss: 0.4509
Epoch: 901, Loss: 0.4548
Epoch: 951, Loss: 0.4519
Epoch: 1001, Loss: 0.4510
Elapsed time 0.1036 min
Epoch: 51, Loss: 0.4831
Epoch: 101, Loss: 0.4880
Epoch: 151, Loss: 0.4528
Epoch: 201, Loss: 0.4492
Epoch: 251, Loss: 0.4445
Epoch: 301, Loss: 0.4485
Epoch: 351, Loss: 0.4422
Epoch: 401, Loss: 0.4410
Epoch: 451, Loss: 0.4402
Epoch: 501, Loss: 0.4372
Epoch: 551, Loss: 0.4420
Epoch: 601, Loss: 0.4374
Epoch: 651, Loss: 0.4369
Epoch: 701, Loss: 0.4343
Epoch: 751, Loss: 0.4378
Epoch: 801, Loss: 0.4343
Epoch: 851, Loss: 0.4724
Epoch: 901, Loss: 0.4509
Epoch: 951, Loss: 0.4634
Epoch: 1001, Loss: 0.4496
Elapsed time 0.1039 min
avg Test Accuracy: 0.7746  avg Test AUC: 0.8107  avg Test PRE: 0.7129
