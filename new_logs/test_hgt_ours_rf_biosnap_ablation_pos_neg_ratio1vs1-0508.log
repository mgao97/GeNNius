====================================================================================================
data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={ edge_index=[2, 13838] },
  (protein, rev_interaction, drug)={ edge_index=[2, 13838] }
)
====================================================================================================
****************************************************************************************************
train data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 7751],
    edge_label=[3874],
    edge_label_index=[2, 3874],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 7751] }
)
****************************************************************************************************
val data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 9688],
    edge_label=[2766],
    edge_label_index=[2, 2766],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 9688] }
)
****************************************************************************************************
test data: HeteroData(
  drug={
    node_id=[4499],
    x=[4499, 12],
  },
  protein={
    node_id=[2113],
    x=[2113, 20],
  },
  (drug, interaction, protein)={
    edge_index=[2, 11071],
    edge_label=[5534],
    edge_label_index=[2, 5534],
  },
  (protein, rev_interaction, drug)={ edge_index=[2, 11071] }
)
****************************************************************************************************
edge_x: torch.Size([3874, 32])
labels: torch.Size([3874])
edge_x: torch.Size([2766, 32])
labels: torch.Size([2766])
edge_x: torch.Size([5534, 32])
labels: torch.Size([5534])
model: HGT(
  (lin_dict): ModuleDict(
    (drug): Linear(-1, 64, bias=True)
    (protein): Linear(-1, 64, bias=True)
  )
  (convs): ModuleList(
    (0-1): 2 x HGTConv(-1, 64, heads=2)
  )
  (lin): Linear(128, 1, bias=True)
)
Epoch: 51, Loss: 0.5551
Epoch: 101, Loss: 0.5443
Epoch: 151, Loss: 0.5409
Epoch: 201, Loss: 0.5385
Epoch: 251, Loss: 0.5333
Epoch: 301, Loss: 0.5352
Epoch: 351, Loss: 0.5194
Epoch: 401, Loss: 0.5172
Epoch: 451, Loss: 0.5166
Epoch: 501, Loss: 0.5166
Epoch: 551, Loss: 0.5146
Epoch: 601, Loss: 0.5122
Epoch: 651, Loss: 0.5107
Epoch: 701, Loss: 0.5101
Epoch: 751, Loss: 0.5098
Epoch: 801, Loss: 0.5095
Epoch: 851, Loss: 0.5084
Epoch: 901, Loss: 0.5120
Epoch: 951, Loss: 0.5072
Epoch: 1001, Loss: 0.5061
Epoch: 51, Loss: 0.5046
Epoch: 101, Loss: 0.5007
Epoch: 151, Loss: 0.4977
Epoch: 201, Loss: 0.4944
Epoch: 251, Loss: 0.4922
Epoch: 301, Loss: 0.4912
Epoch: 351, Loss: 0.4935
Epoch: 401, Loss: 0.4909
Epoch: 451, Loss: 0.4883
Epoch: 501, Loss: 0.4882
Epoch: 551, Loss: 0.4888
Epoch: 601, Loss: 0.4884
Epoch: 651, Loss: 0.5303
Epoch: 701, Loss: 0.5035
Epoch: 751, Loss: 0.4961
Epoch: 801, Loss: 0.5633
Epoch: 851, Loss: 0.5172
Epoch: 901, Loss: 0.5159
Epoch: 951, Loss: 0.5150
Epoch: 1001, Loss: 0.5144
Elapsed time 0.0754 min
Epoch: 51, Loss: 0.5140
Epoch: 101, Loss: 0.5136
Epoch: 151, Loss: 0.5132
Epoch: 201, Loss: 0.5125
Epoch: 251, Loss: 0.5118
Epoch: 301, Loss: 0.5106
Epoch: 351, Loss: 0.5092
Epoch: 401, Loss: 0.5078
Epoch: 451, Loss: 0.5068
Epoch: 501, Loss: 0.5060
Epoch: 551, Loss: 0.5053
Epoch: 601, Loss: 0.5048
Epoch: 651, Loss: 0.5042
Epoch: 701, Loss: 0.5036
Epoch: 751, Loss: 0.5029
Epoch: 801, Loss: 0.5022
Epoch: 851, Loss: 0.5015
Epoch: 901, Loss: 0.5008
Epoch: 951, Loss: 0.5002
Epoch: 1001, Loss: 0.4996
Elapsed time 0.0734 min
Epoch: 51, Loss: 0.4991
Epoch: 101, Loss: 0.4986
Epoch: 151, Loss: 0.4980
Epoch: 201, Loss: 0.4975
Epoch: 251, Loss: 0.4971
Epoch: 301, Loss: 0.4967
Epoch: 351, Loss: 0.4963
Epoch: 401, Loss: 0.4959
Epoch: 451, Loss: 0.4961
Epoch: 501, Loss: 0.4957
Epoch: 551, Loss: 0.4959
Epoch: 601, Loss: 0.4953
Epoch: 651, Loss: 0.4939
Epoch: 701, Loss: 0.4937
Epoch: 751, Loss: 0.4914
Epoch: 801, Loss: 0.4908
Epoch: 851, Loss: 0.4895
Epoch: 901, Loss: 0.5524
Epoch: 951, Loss: 0.4932
Epoch: 1001, Loss: 0.4924
Elapsed time 0.0757 min
Epoch: 51, Loss: 0.4919
Epoch: 101, Loss: 0.4914
Epoch: 151, Loss: 0.4910
Epoch: 201, Loss: 0.4905
Epoch: 251, Loss: 0.4902
Epoch: 301, Loss: 0.4898
Epoch: 351, Loss: 0.4895
Epoch: 401, Loss: 0.4891
Epoch: 451, Loss: 0.4887
Epoch: 501, Loss: 0.4884
Epoch: 551, Loss: 0.4881
Epoch: 601, Loss: 0.4894
Epoch: 651, Loss: 0.4876
Epoch: 701, Loss: 0.4875
Epoch: 751, Loss: 0.4880
Epoch: 801, Loss: 0.4869
Epoch: 851, Loss: 0.4872
Epoch: 901, Loss: 0.4875
Epoch: 951, Loss: 0.4864
Epoch: 1001, Loss: 0.4868
Elapsed time 0.0757 min
Epoch: 51, Loss: 0.4865
Epoch: 101, Loss: 0.4862
Epoch: 151, Loss: 0.4858
Epoch: 201, Loss: 0.4857
Epoch: 251, Loss: 0.4856
Epoch: 301, Loss: 0.4858
Epoch: 351, Loss: 0.4856
Epoch: 401, Loss: 0.4857
Epoch: 451, Loss: 0.4852
Epoch: 501, Loss: 0.4851
Epoch: 551, Loss: 0.4853
Epoch: 601, Loss: 0.4851
Epoch: 651, Loss: 0.4852
Epoch: 701, Loss: 0.4846
Epoch: 751, Loss: 0.4846
Epoch: 801, Loss: 0.4845
Epoch: 851, Loss: 0.4844
Epoch: 901, Loss: 0.4846
Epoch: 951, Loss: 0.4844
Epoch: 1001, Loss: 0.4853
Elapsed time 0.0754 min
Epoch: 51, Loss: 0.4841
Epoch: 101, Loss: 0.4839
Epoch: 151, Loss: 0.4844
Epoch: 201, Loss: 0.4834
Epoch: 251, Loss: 0.4833
Epoch: 301, Loss: 0.4825
Epoch: 351, Loss: 0.4820
Epoch: 401, Loss: 0.4821
Epoch: 451, Loss: 0.4818
Epoch: 501, Loss: 0.4816
Epoch: 551, Loss: 0.4822
Epoch: 601, Loss: 0.4815
Epoch: 651, Loss: 0.4814
Epoch: 701, Loss: 0.4809
Epoch: 751, Loss: 0.4805
Epoch: 801, Loss: 0.4824
Epoch: 851, Loss: 0.4802
Epoch: 901, Loss: 0.4801
Epoch: 951, Loss: 0.4805
Epoch: 1001, Loss: 0.4799
Elapsed time 0.0756 min
Epoch: 51, Loss: 0.4799
Epoch: 101, Loss: 0.4798
Epoch: 151, Loss: 0.4833
Epoch: 201, Loss: 0.4801
Epoch: 251, Loss: 0.4798
Epoch: 301, Loss: 0.4791
Epoch: 351, Loss: 0.4812
Epoch: 401, Loss: 0.4796
Epoch: 451, Loss: 0.4795
Epoch: 501, Loss: 0.4788
Epoch: 551, Loss: 0.4794
Epoch: 601, Loss: 0.4793
Epoch: 651, Loss: 0.4808
Epoch: 701, Loss: 0.4778
Epoch: 751, Loss: 0.4773
Epoch: 801, Loss: 0.4859
Epoch: 851, Loss: 0.4801
Epoch: 901, Loss: 0.4797
Epoch: 951, Loss: 0.4783
Epoch: 1001, Loss: 0.4803
Elapsed time 0.0732 min
Epoch: 51, Loss: 0.4789
Epoch: 101, Loss: 0.4791
Epoch: 151, Loss: 0.4795
Epoch: 201, Loss: 0.4789
Epoch: 251, Loss: 0.4802
Epoch: 301, Loss: 0.4788
Epoch: 351, Loss: 0.4785
Epoch: 401, Loss: 0.4798
Epoch: 451, Loss: 0.4799
Epoch: 501, Loss: 0.4787
Epoch: 551, Loss: 0.4803
Epoch: 601, Loss: 0.4786
Epoch: 651, Loss: 0.4798
Epoch: 701, Loss: 0.4824
Epoch: 751, Loss: 0.4785
Epoch: 801, Loss: 0.4790
Epoch: 851, Loss: 0.4791
Epoch: 901, Loss: 0.5106
Epoch: 951, Loss: 0.4805
Epoch: 1001, Loss: 0.4796
Elapsed time 0.0755 min
Epoch: 51, Loss: 0.4783
Epoch: 101, Loss: 0.4781
Epoch: 151, Loss: 0.4778
Epoch: 201, Loss: 0.4907
Epoch: 251, Loss: 0.4787
Epoch: 301, Loss: 0.4787
Epoch: 351, Loss: 0.4782
Epoch: 401, Loss: 0.4778
Epoch: 451, Loss: 0.4780
Epoch: 501, Loss: 0.4777
Epoch: 551, Loss: 0.4777
Epoch: 601, Loss: 0.4944
Epoch: 651, Loss: 0.4829
Epoch: 701, Loss: 0.4779
Epoch: 751, Loss: 0.4777
Epoch: 801, Loss: 0.4776
Epoch: 851, Loss: 0.4775
Epoch: 901, Loss: 0.4775
Epoch: 951, Loss: 0.4774
Epoch: 1001, Loss: 0.4778
Elapsed time 0.0755 min
Epoch: 51, Loss: 0.4775
Epoch: 101, Loss: 0.4774
Epoch: 151, Loss: 0.4774
Epoch: 201, Loss: 0.4774
Epoch: 251, Loss: 0.4773
Epoch: 301, Loss: 0.4773
Epoch: 351, Loss: 0.4773
Epoch: 401, Loss: 0.4773
Epoch: 451, Loss: 0.4801
Epoch: 501, Loss: 0.4788
Epoch: 551, Loss: 0.4788
Epoch: 601, Loss: 0.4930
Epoch: 651, Loss: 0.4788
Epoch: 701, Loss: 0.4875
Epoch: 751, Loss: 0.4790
Epoch: 801, Loss: 0.4866
Epoch: 851, Loss: 0.4832
Epoch: 901, Loss: 0.4784
Epoch: 951, Loss: 0.4779
Epoch: 1001, Loss: 0.4778
Elapsed time 0.0754 min
avg Test Accuracy: 0.7815  avg Test AUC: 0.8627  avg Test PRE: 0.7999
